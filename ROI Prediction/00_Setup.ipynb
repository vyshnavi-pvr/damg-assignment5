{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup or Reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Warning!!!!\n",
    "### Running this code will delete an existing database as specified in the state dictionary below.\n",
    "\n",
    "We need a way to save state throughout the project.  We will initially login as the ACCOUNTADMIN role in order to setup some additional users as well as the compute resources we will need. \n",
    "\n",
    "We will specify a couple of different compute resources which allows us to scale up and down easily.  Most of the workflow can use an extra-small warehouse but for certain tasks (ie. feature engineering and model training) we may need larger compute.  By specifying them in the state dictionary we can easily select the correct compute for any particular task.\n",
    "  \n",
    "Update the \\<USERNAME>, \\<ACCOUNTNAME>, \\<DOMAIN> in the state dictionary below with the initial user that was created with your trial account.\n",
    "\n",
    "Note: If you are running the US West (Oregon) region, you don't need to add the \\<DOMAIN>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = { \n",
    "  \"account\"   : \"neb77596.us-east-1\",\n",
    "  \"user\"      : \"Vyshnavi24\",\n",
    "  \"password\"  : \"Yukti@24\",\n",
    "  \"role\"      : \"ORGADMIN\",\n",
    "  \"warehouse\" : \"A5_WH\",\n",
    "  \"database\"  : \"A5_DB\",\n",
    "  \"schema\"    : \"A5_SCHEMA\"\n",
    "                            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./connection.json', 'w') as sdf:\n",
    "    json.dump(state_dict, sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will connect with username and password.  In a non-demo system it is very important to use properly secured passwords with secret managers and/or oauth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter password for user with ACCOUNTADMIN role access ········\n"
     ]
    }
   ],
   "source": [
    "import snowflake.snowpark as snp\n",
    "import json\n",
    "import getpass\n",
    "\n",
    "account_admin_password = getpass.getpass('Enter password for user with ACCOUNTADMIN role access')\n",
    "\n",
    "with open('./connection.json') as sdf:\n",
    "    state_dict = json.load(sdf)    \n",
    "state_dict['password'] = account_admin_password\n",
    "\n",
    "session = snp.Session.builder.configs(state_dict).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.use_role('ACCOUNTADMIN')\n",
    "\n",
    "demo_username='jack'\n",
    "project_role='dash_ds'\n",
    "\n",
    "session.sql(\"CREATE USER IF NOT EXISTS \"+demo_username+\\\n",
    "            \" LOGIN_NAME = '\"+demo_username+\"'\"+\\\n",
    "            \" FIRST_NAME = 'SNOWPARK'\"+\\\n",
    "            \" LAST_NAME = 'HOL'\"+\\\n",
    "            \" EMAIL = 'jack@hol.snowpark'\"+\\\n",
    "            \" DEFAULT_ROLE = '\"+project_role+\"'\"+\\\n",
    "            \" MUST_CHANGE_PASSWORD = FALSE\")\\\n",
    "        .collect()\n",
    "\n",
    "session.sql(\"GRANT ROLE \"+project_role+\" TO USER \"+demo_username).collect()\n",
    "\n",
    "session.use_role('sysadmin')\n",
    "session.sql(\"GRANT CREATE DATABASE ON ACCOUNT TO ROLE \"+project_role).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.use_role('ACCOUNTADMIN')\n",
    "\n",
    "\n",
    "session.sql(\"CREATE WAREHOUSE IF NOT EXISTS A5_WH \\\n",
    "            WITH WAREHOUSE_SIZE = 'SMALL' \\\n",
    "            WAREHOUSE_TYPE = 'STANDARD' AUTO_SUSPEND = 60\\\n",
    "            AUTO_RESUME = TRUE initially_suspended = true;\")\\\n",
    "            .collect()\n",
    "\n",
    "session.sql(\"GRANT ALL ON WAREHOUSE A5_WH TO ROLE DASH_DS\").collect() \n",
    "session.sql(\"GRANT ALL ON DATABASE A5_DB TO ROLE DASH_DS\").collect() \n",
    "session.sql(\"GRANT ALL ON SCHEMA A5_SCHEMA TO ROLE DASH_DS\").collect()\n",
    "    \n",
    "# session.use_role(state_dict['connection_parameters']['role'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.use_role('ACCOUNTADMIN')\n",
    "# # session.sql(\"GRANT IMPORT SHARE ON ACCOUNT TO DASH_DS\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"A5_WH\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_current_warehouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing include/snowpark_connection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile include/snowpark_connection.py\n",
    "def snowpark_connect(state_file='./connection.json'):\n",
    "    import snowflake.snowpark as snp\n",
    "    import json\n",
    "    \n",
    "    with open(state_file) as sdf:\n",
    "        state_dict = json.load(sdf)    \n",
    "    \n",
    "    session=None\n",
    "    session = snp.Session.builder.configs(state_dict).create()\n",
    "    session.use_warehouse(state_dict['warehouse'])\n",
    "    return session, state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from include.snowpark_connection import snowpark_connect\n",
    "session, state_dict = snowpark_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_current_warehouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"GRANT ALL on TABLE CLICK_DATA to ROLE DASH_DS\").collect()\n",
    "session.sql(\"GRANT ALL on TABLE BUDGET_ALLOCATIONS_AND_ROI to ROLE DASH_DS\").collect()\n",
    "session.sql(\"GRANT ALL on TABLE CAMPAIGN_SPEND to ROLE DASH_DS\").collect()\n",
    "session.sql(\"GRANT ALL on TABLE MONTHLY_REVENUE to ROLE DASH_DS;\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"GRANT ALL on STAGE dash_models to ROLE DASH_DS\").collect()\n",
    "session.sql(\"GRANT ALL on STAGE dash_udfs to ROLE DASH_DS\").collect()\n",
    "session.sql(\"GRANT ALL on STAGE dash_sprocs to ROLE DASH_DS\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"ALTER tag PII unset masking policy MASK_PII\").collect()\n",
    "session.sql(\"ALTER TABLE CLICK_DATA unset tag PII\").collect()\n",
    "session.sql(\"DROP tag IF EXISTS PII\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=0, COST=1.6573384192760834, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693290),\n",
       " Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=0, COST=0.583065454070374, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693320),\n",
       " Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=1, COST=3.6390632787126926, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693350),\n",
       " Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=0, COST=6.042860165727694, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693380),\n",
       " Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=1, COST=7.074881873926015, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693410),\n",
       " Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=0, COST=2.927477923943971, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693440),\n",
       " Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=0, COST=2.6065561321708173, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693470),\n",
       " Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=1, COST=3.5846603994704735, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693500),\n",
       " Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=0, COST=2.200923861159916, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693530),\n",
       " Row(AD_ID='***MASKED***', CHANNEL='***MASKED***', CLICK=0, COST=1.7216264347568893, IPADDRESS='***MASKED***', MACADDRESS='***MASKED***', TIMESTAMP=1552693560)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"CREATE OR REPLACE tag PII\").collect()\n",
    "  \n",
    "session.sql(\"CREATE OR REPLACE masking policy MASK_PII as (val string) returns string ->\\\n",
    "  case\\\n",
    "    when current_role() IN ('ACCOUNTADMIN') then val\\\n",
    "    when current_role() IN ('DASH_DS') then '***MASKED***'\\\n",
    "  end\").collect()\n",
    "  \n",
    "session.sql(\"ALTER tag PII set masking policy MASK_PII\").collect()\n",
    "\n",
    "session.sql(\"ALTER TABLE CLICK_DATA set tag PII = 'tag-based policies'\").collect()\n",
    "\n",
    "# -- NOTE: To test the above masking policy, run the follwing queries. \n",
    "# -- When using ACCOUNTADMIN role you should see plain-text values for all the columns. \n",
    "# -- When using DASH_DS role you should see \"***MASKED***\" values for AD_ID, CHANNEL, IPADDRESS, and MACADDRESS columns.\n",
    "\n",
    "session.sql(\"GRANT ROLE DASH_DS to USER Vyshnavi24\").collect()\n",
    "\n",
    "session.use_role('ACCOUNTADMIN')\n",
    "session.sql(\"SELECT * from CLICK_DATA limit 10\").collect()\n",
    "\n",
    "session.use_role('DASH_DS')\n",
    "session.sql(\"SELECT * from CLICK_DATA limit 10\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use a specific AWS S3 role for accessing pre-staged files to speed up the hands-on-lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict['connection_parameters']['download_base_url'] = 's3://sfquickstarts/Summit 2022 Keynote Demo/click_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this without access to pre-staged files run the following cell instead of the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict['connection_parameters']['download_base_url'] = 'https://s3.amazonaws.com/tripdata/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sample user which will be used for the hands-on-lab.  Normally you will have different roles (and possibly different users) for data scientists, data engineers, ML engineers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.use_role('ACCOUNTADMIN')\n",
    "\n",
    "# demo_username='jack'\n",
    "# project_role='ACCOUNTADMIN'\n",
    "\n",
    "# session.sql(\"CREATE USER IF NOT EXISTS \"+demo_username+\\\n",
    "#             \" LOGIN_NAME = '\"+demo_username+\"'\"+\\\n",
    "#             \" FIRST_NAME = 'SNOWPARK'\"+\\\n",
    "#             \" LAST_NAME = 'HOL'\"+\\\n",
    "#             \" EMAIL = 'jack@hol.snowpark'\"+\\\n",
    "#             \" DEFAULT_ROLE = '\"+project_role+\"'\"+\\\n",
    "#             \" MUST_CHANGE_PASSWORD = FALSE\")\\\n",
    "#         .collect()\n",
    "\n",
    "# session.sql(\"GRANT ROLE \"+project_role+\" TO USER \"+demo_username).collect()\n",
    "\n",
    "# session.use_role('sysadmin')\n",
    "# session.sql(\"GRANT CREATE DATABASE ON ACCOUNT TO ROLE \"+project_role).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.use_role('ACCOUNTADMIN')\n",
    "# project_role='ACCOUNTADMIN'\n",
    "\n",
    "# session.sql(\"CREATE WAREHOUSE IF NOT EXISTS A5_WH \\\n",
    "#             WITH WAREHOUSE_SIZE = 'SMALL' \\\n",
    "#             WAREHOUSE_TYPE = 'STANDARD' AUTO_SUSPEND = 60\\\n",
    "#             AUTO_RESUME = TRUE initially_suspended = true;\")\\\n",
    "#             .collect()\n",
    "\n",
    "# session.sql(\"GRANT USAGE ON WAREHOUSE A5_WH TO ROLE DASH_DS\").collect() \n",
    "# session.sql(\"GRANT OPERATE ON WAREHOUSE A5_WH TO ROLE DASH_DS\").collect() \n",
    "    \n",
    "# # session.use_role(state_dict['connection_parameters']['role'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# session.use_role('securityadmin')\n",
    "# demo_user_password=getpass.getpass('Enter a new password for the demo user '+demo_username)\n",
    "# session.sql(\"ALTER USER \"+demo_username+\" SET PASSWORD = '\"+demo_user_password+\"'\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create compute instances as specified in the state dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.use_role('ACCOUNTADMIN')\n",
    "# project_role='ACCOUNTADMIN'\n",
    "\n",
    "# for wh in state_dict['compute_parameters'].values():\n",
    "#     if wh != \"train_warehouse\":\n",
    "#         session.sql(\"CREATE WAREHOUSE IF NOT EXISTS \"+wh+\\\n",
    "#                 \" WITH WAREHOUSE_SIZE = '\"+wh.split('_')[0]+\\\n",
    "#                 \"' WAREHOUSE_TYPE = 'STANDARD' AUTO_SUSPEND = 60 AUTO_RESUME = TRUE initially_suspended = true;\")\\\n",
    "#             .collect()\n",
    "#     elif wh == \"train_warehouse\":\n",
    "#         session.sql(\"CREATE WAREHOUSE IF NOT EXISTS \"+wh+\\\n",
    "#                 \" WITH WAREHOUSE_SIZE = '\"+wh.split('_')[0]+\\\n",
    "#                 \"' WAREHOUSE_TYPE = 'HIGH_MEMORY' MAX_CONCURRENCY_LEVEL = 1 AUTO_SUSPEND = 60 AUTO_RESUME = TRUE initially_suspended = true;\")\\\n",
    "#             .collect()\n",
    "#     session.sql(\"GRANT USAGE ON WAREHOUSE \"+wh+\" TO ROLE \"+project_role).collect() \n",
    "#     session.sql(\"GRANT OPERATE ON WAREHOUSE \"+wh+\" TO ROLE \"+project_role).collect() \n",
    "    \n",
    "# session.use_role(state_dict['connection_parameters']['role'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow users to import data shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# session.use_role('ACCOUNTADMIN')\n",
    "# session.sql(\"GRANT IMPORT SHARE ON ACCOUNT TO \"+project_role).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now update the state dictionary to use the non-admin account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict['connection_parameters']['user'] = demo_username\n",
    "# state_dict['connection_parameters']['password'] = demo_user_password\n",
    "# state_dict['connection_parameters']['role'] = project_role\n",
    "# state_dict['connection_parameters']['database'] = 'Assignment4_'+demo_username\n",
    "# state_dict['connection_parameters']['schema'] = 'DEMO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the updated state dictionary for project team use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('./connection.json', 'w') as sdf:\n",
    "#     json.dump(state_dict, sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a python function to simplify the users' steps of starting a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dags/snowpark_connection.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile dags/snowpark_connection.py\n",
    "# def snowpark_connect(state_file='./connection.json'):\n",
    "#     import snowflake.snowpark as snp\n",
    "#     import json\n",
    "    \n",
    "#     with open(state_file) as sdf:\n",
    "#         state_dict = json.load(sdf)    \n",
    "    \n",
    "#     session=None\n",
    "#     session = snp.Session.builder.configs(state_dict[\"connection_parameters\"]).create()\n",
    "#     session.use_warehouse(state_dict['compute_parameters']['default_warehouse'])\n",
    "#     return session, state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function that users will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dags.snowpark_connection import snowpark_connect\n",
    "# session, state_dict = snowpark_connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the user has access to each compute instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"A5_WH\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# session.get_current_warehouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for wh in state_dict['compute_parameters'].keys():\n",
    "#     session.use_warehouse(state_dict['compute_parameters'][wh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"XXLARGE_SNOWPARKOPT_WH\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# session.get_current_warehouse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the database and schema for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "cforbe"
   }
  ],
  "kernelspec": {
   "display_name": "snowpark_0110:Python",
   "language": "python",
   "name": "conda-env-snowpark_0110-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "msauthor": "trbye",
  "vscode": {
   "interpreter": {
    "hash": "2614690ea9fbd59ba0b6237432366eb3dd6a41bb6a55e6e289aa8513f88de2ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
